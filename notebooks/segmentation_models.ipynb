{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "eefe3629",
   "metadata": {},
   "source": [
    "# **COMP9517 - Group Project (Segmentation Models Pytorch)**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb76af11",
   "metadata": {},
   "source": [
    "## **0. Add Imports**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "16f037ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !conda env create -f environment.yaml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "45474d93",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "sys.path.append(os.path.join(os.getcwd(), \"..\"))\n",
    "\n",
    "import lightning as L\n",
    "from lightning.pytorch.callbacks import ModelCheckpoint, LearningRateMonitor, EarlyStopping, RichProgressBar, RichModelSummary\n",
    "from lightning.pytorch.loggers import TensorBoardLogger, WandbLogger\n",
    "\n",
    "from data import AerialDeadTreeSegDataModule, download_dataset\n",
    "from lightning.pytorch.tuner import Tuner\n",
    "from lightning_modules import SMPLitModule\n",
    "from models import FreezeSMPEncoderUtils\n",
    "from utils import paths,TimerCallback\n",
    "import segmentation_models_pytorch as smp\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6bfcd838",
   "metadata": {},
   "outputs": [],
   "source": [
    "ARCH = \"UNet\"\n",
    "ENCODER_NAME = \"mit_b5\"\n",
    "VERSION = \"val_transform_test2\"\n",
    "TARGET_SIZE = 256\n",
    "LOSS1 = smp.losses.JaccardLoss(mode='binary', from_logits=True)\n",
    "LOSS2 = smp.losses.FocalLoss(mode='binary')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bfbd7cde",
   "metadata": {},
   "source": [
    "## **1. Simple Summary of the Dattaset**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8ed9f2b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max RGB resolution: (652, 636), Min RGB resolution: (317, 294)\n",
      "Max NRG resolution: (652, 636), Min NRG resolution: (317, 294)\n"
     ]
    }
   ],
   "source": [
    "from PIL import Image\n",
    "# Get the data folder\n",
    "data_folder = download_dataset()\n",
    "\n",
    "rgb_dir = os.path.join(data_folder, \"RGB_images\")\n",
    "nrg_dir = os.path.join(data_folder, \"NRG_images\")\n",
    "mask_dir = os.path.join(data_folder, \"masks\")\n",
    "\n",
    "# Get the max and min resolution of the images\n",
    "def get_max_min_resolution(image_dir):\n",
    "    max_res = (0, 0)\n",
    "    min_res = (float('inf'), float('inf'))\n",
    "    for filename in os.listdir(image_dir):\n",
    "        if filename.endswith(\".png\"):\n",
    "            filepath = os.path.join(image_dir, filename)\n",
    "            with open(filepath, 'rb') as f:\n",
    "                img = Image.open(f)\n",
    "                height, width = img.size\n",
    "                max_res = (max(max_res[0], height), max(max_res[1], width))\n",
    "                min_res = (min(min_res[0], height), min(min_res[1], width))\n",
    "    return max_res, min_res\n",
    "max_rgb_res, min_rgb_res = get_max_min_resolution(rgb_dir)\n",
    "max_nrg_res, min_nrg_res = get_max_min_resolution(nrg_dir)\n",
    "print(f\"Max RGB resolution: {max_rgb_res}, Min RGB resolution: {min_rgb_res}\")\n",
    "print(f\"Max NRG resolution: {max_nrg_res}, Min NRG resolution: {min_nrg_res}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7db092b",
   "metadata": {},
   "source": [
    "## **1. Find Suggested Learning Rate**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2df12677",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_module = AerialDeadTreeSegDataModule(\n",
    "    val_split=0.1, test_split=0.2, seed=42,\n",
    "    modality=\"merged\", # in_channels=4. If modality is \"merged\", it will use 4 channels (RGB + NIR); Otherwise, it will use 3 channels (RGB).\n",
    "    batch_size=32,\n",
    "    num_workers= int(os.cpu_count() / 2) if os.cpu_count() is not None else 0,\n",
    "    target_size=TARGET_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "03d1d709",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Layer: patch_embed1, Module: OverlapPatchEmbed(\n",
      "  (proj): Conv2d(4, 64, kernel_size=(7, 7), stride=(4, 4), padding=(3, 3))\n",
      "  (norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
      ")\n",
      "Layer: patch_embed2, Module: OverlapPatchEmbed(\n",
      "  (proj): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
      "  (norm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
      ")\n",
      "Layer: patch_embed3, Module: OverlapPatchEmbed(\n",
      "  (proj): Conv2d(128, 320, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
      "  (norm): LayerNorm((320,), eps=1e-05, elementwise_affine=True)\n",
      ")\n",
      "Layer: patch_embed4, Module: OverlapPatchEmbed(\n",
      "  (proj): Conv2d(320, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
      "  (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
      ")\n",
      "Layer: block1, Module: Sequential(\n",
      "  (0): Block(\n",
      "    (norm1): LayerNorm((64,), eps=1e-06, elementwise_affine=True)\n",
      "    (attn): Attention(\n",
      "      (q): Linear(in_features=64, out_features=64, bias=True)\n",
      "      (kv): Linear(in_features=64, out_features=128, bias=True)\n",
      "      (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "      (proj): Linear(in_features=64, out_features=64, bias=True)\n",
      "      (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "      (sr): Conv2d(64, 64, kernel_size=(8, 8), stride=(8, 8))\n",
      "      (norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
      "    )\n",
      "    (drop_path): Identity()\n",
      "    (norm2): LayerNorm((64,), eps=1e-06, elementwise_affine=True)\n",
      "    (mlp): Mlp(\n",
      "      (fc1): Linear(in_features=64, out_features=256, bias=True)\n",
      "      (dwconv): DWConv(\n",
      "        (dwconv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=256)\n",
      "      )\n",
      "      (act): GELU(approximate='none')\n",
      "      (fc2): Linear(in_features=256, out_features=64, bias=True)\n",
      "      (drop): Dropout(p=0.0, inplace=False)\n",
      "    )\n",
      "  )\n",
      "  (1): Block(\n",
      "    (norm1): LayerNorm((64,), eps=1e-06, elementwise_affine=True)\n",
      "    (attn): Attention(\n",
      "      (q): Linear(in_features=64, out_features=64, bias=True)\n",
      "      (kv): Linear(in_features=64, out_features=128, bias=True)\n",
      "      (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "      (proj): Linear(in_features=64, out_features=64, bias=True)\n",
      "      (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "      (sr): Conv2d(64, 64, kernel_size=(8, 8), stride=(8, 8))\n",
      "      (norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
      "    )\n",
      "    (drop_path): DropPath(drop_prob=0.002)\n",
      "    (norm2): LayerNorm((64,), eps=1e-06, elementwise_affine=True)\n",
      "    (mlp): Mlp(\n",
      "      (fc1): Linear(in_features=64, out_features=256, bias=True)\n",
      "      (dwconv): DWConv(\n",
      "        (dwconv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=256)\n",
      "      )\n",
      "      (act): GELU(approximate='none')\n",
      "      (fc2): Linear(in_features=256, out_features=64, bias=True)\n",
      "      (drop): Dropout(p=0.0, inplace=False)\n",
      "    )\n",
      "  )\n",
      "  (2): Block(\n",
      "    (norm1): LayerNorm((64,), eps=1e-06, elementwise_affine=True)\n",
      "    (attn): Attention(\n",
      "      (q): Linear(in_features=64, out_features=64, bias=True)\n",
      "      (kv): Linear(in_features=64, out_features=128, bias=True)\n",
      "      (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "      (proj): Linear(in_features=64, out_features=64, bias=True)\n",
      "      (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "      (sr): Conv2d(64, 64, kernel_size=(8, 8), stride=(8, 8))\n",
      "      (norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
      "    )\n",
      "    (drop_path): DropPath(drop_prob=0.004)\n",
      "    (norm2): LayerNorm((64,), eps=1e-06, elementwise_affine=True)\n",
      "    (mlp): Mlp(\n",
      "      (fc1): Linear(in_features=64, out_features=256, bias=True)\n",
      "      (dwconv): DWConv(\n",
      "        (dwconv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=256)\n",
      "      )\n",
      "      (act): GELU(approximate='none')\n",
      "      (fc2): Linear(in_features=256, out_features=64, bias=True)\n",
      "      (drop): Dropout(p=0.0, inplace=False)\n",
      "    )\n",
      "  )\n",
      ")\n",
      "Layer: norm1, Module: LayerNorm((64,), eps=1e-06, elementwise_affine=True)\n",
      "Layer: block2, Module: Sequential(\n",
      "  (0): Block(\n",
      "    (norm1): LayerNorm((128,), eps=1e-06, elementwise_affine=True)\n",
      "    (attn): Attention(\n",
      "      (q): Linear(in_features=128, out_features=128, bias=True)\n",
      "      (kv): Linear(in_features=128, out_features=256, bias=True)\n",
      "      (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "      (proj): Linear(in_features=128, out_features=128, bias=True)\n",
      "      (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "      (sr): Conv2d(128, 128, kernel_size=(4, 4), stride=(4, 4))\n",
      "      (norm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
      "    )\n",
      "    (drop_path): DropPath(drop_prob=0.006)\n",
      "    (norm2): LayerNorm((128,), eps=1e-06, elementwise_affine=True)\n",
      "    (mlp): Mlp(\n",
      "      (fc1): Linear(in_features=128, out_features=512, bias=True)\n",
      "      (dwconv): DWConv(\n",
      "        (dwconv): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=512)\n",
      "      )\n",
      "      (act): GELU(approximate='none')\n",
      "      (fc2): Linear(in_features=512, out_features=128, bias=True)\n",
      "      (drop): Dropout(p=0.0, inplace=False)\n",
      "    )\n",
      "  )\n",
      "  (1): Block(\n",
      "    (norm1): LayerNorm((128,), eps=1e-06, elementwise_affine=True)\n",
      "    (attn): Attention(\n",
      "      (q): Linear(in_features=128, out_features=128, bias=True)\n",
      "      (kv): Linear(in_features=128, out_features=256, bias=True)\n",
      "      (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "      (proj): Linear(in_features=128, out_features=128, bias=True)\n",
      "      (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "      (sr): Conv2d(128, 128, kernel_size=(4, 4), stride=(4, 4))\n",
      "      (norm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
      "    )\n",
      "    (drop_path): DropPath(drop_prob=0.008)\n",
      "    (norm2): LayerNorm((128,), eps=1e-06, elementwise_affine=True)\n",
      "    (mlp): Mlp(\n",
      "      (fc1): Linear(in_features=128, out_features=512, bias=True)\n",
      "      (dwconv): DWConv(\n",
      "        (dwconv): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=512)\n",
      "      )\n",
      "      (act): GELU(approximate='none')\n",
      "      (fc2): Linear(in_features=512, out_features=128, bias=True)\n",
      "      (drop): Dropout(p=0.0, inplace=False)\n",
      "    )\n",
      "  )\n",
      "  (2): Block(\n",
      "    (norm1): LayerNorm((128,), eps=1e-06, elementwise_affine=True)\n",
      "    (attn): Attention(\n",
      "      (q): Linear(in_features=128, out_features=128, bias=True)\n",
      "      (kv): Linear(in_features=128, out_features=256, bias=True)\n",
      "      (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "      (proj): Linear(in_features=128, out_features=128, bias=True)\n",
      "      (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "      (sr): Conv2d(128, 128, kernel_size=(4, 4), stride=(4, 4))\n",
      "      (norm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
      "    )\n",
      "    (drop_path): DropPath(drop_prob=0.010)\n",
      "    (norm2): LayerNorm((128,), eps=1e-06, elementwise_affine=True)\n",
      "    (mlp): Mlp(\n",
      "      (fc1): Linear(in_features=128, out_features=512, bias=True)\n",
      "      (dwconv): DWConv(\n",
      "        (dwconv): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=512)\n",
      "      )\n",
      "      (act): GELU(approximate='none')\n",
      "      (fc2): Linear(in_features=512, out_features=128, bias=True)\n",
      "      (drop): Dropout(p=0.0, inplace=False)\n",
      "    )\n",
      "  )\n",
      "  (3): Block(\n",
      "    (norm1): LayerNorm((128,), eps=1e-06, elementwise_affine=True)\n",
      "    (attn): Attention(\n",
      "      (q): Linear(in_features=128, out_features=128, bias=True)\n",
      "      (kv): Linear(in_features=128, out_features=256, bias=True)\n",
      "      (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "      (proj): Linear(in_features=128, out_features=128, bias=True)\n",
      "      (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "      (sr): Conv2d(128, 128, kernel_size=(4, 4), stride=(4, 4))\n",
      "      (norm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
      "    )\n",
      "    (drop_path): DropPath(drop_prob=0.012)\n",
      "    (norm2): LayerNorm((128,), eps=1e-06, elementwise_affine=True)\n",
      "    (mlp): Mlp(\n",
      "      (fc1): Linear(in_features=128, out_features=512, bias=True)\n",
      "      (dwconv): DWConv(\n",
      "        (dwconv): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=512)\n",
      "      )\n",
      "      (act): GELU(approximate='none')\n",
      "      (fc2): Linear(in_features=512, out_features=128, bias=True)\n",
      "      (drop): Dropout(p=0.0, inplace=False)\n",
      "    )\n",
      "  )\n",
      "  (4): Block(\n",
      "    (norm1): LayerNorm((128,), eps=1e-06, elementwise_affine=True)\n",
      "    (attn): Attention(\n",
      "      (q): Linear(in_features=128, out_features=128, bias=True)\n",
      "      (kv): Linear(in_features=128, out_features=256, bias=True)\n",
      "      (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "      (proj): Linear(in_features=128, out_features=128, bias=True)\n",
      "      (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "      (sr): Conv2d(128, 128, kernel_size=(4, 4), stride=(4, 4))\n",
      "      (norm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
      "    )\n",
      "    (drop_path): DropPath(drop_prob=0.014)\n",
      "    (norm2): LayerNorm((128,), eps=1e-06, elementwise_affine=True)\n",
      "    (mlp): Mlp(\n",
      "      (fc1): Linear(in_features=128, out_features=512, bias=True)\n",
      "      (dwconv): DWConv(\n",
      "        (dwconv): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=512)\n",
      "      )\n",
      "      (act): GELU(approximate='none')\n",
      "      (fc2): Linear(in_features=512, out_features=128, bias=True)\n",
      "      (drop): Dropout(p=0.0, inplace=False)\n",
      "    )\n",
      "  )\n",
      "  (5): Block(\n",
      "    (norm1): LayerNorm((128,), eps=1e-06, elementwise_affine=True)\n",
      "    (attn): Attention(\n",
      "      (q): Linear(in_features=128, out_features=128, bias=True)\n",
      "      (kv): Linear(in_features=128, out_features=256, bias=True)\n",
      "      (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "      (proj): Linear(in_features=128, out_features=128, bias=True)\n",
      "      (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "      (sr): Conv2d(128, 128, kernel_size=(4, 4), stride=(4, 4))\n",
      "      (norm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
      "    )\n",
      "    (drop_path): DropPath(drop_prob=0.016)\n",
      "    (norm2): LayerNorm((128,), eps=1e-06, elementwise_affine=True)\n",
      "    (mlp): Mlp(\n",
      "      (fc1): Linear(in_features=128, out_features=512, bias=True)\n",
      "      (dwconv): DWConv(\n",
      "        (dwconv): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=512)\n",
      "      )\n",
      "      (act): GELU(approximate='none')\n",
      "      (fc2): Linear(in_features=512, out_features=128, bias=True)\n",
      "      (drop): Dropout(p=0.0, inplace=False)\n",
      "    )\n",
      "  )\n",
      ")\n",
      "Layer: norm2, Module: LayerNorm((128,), eps=1e-06, elementwise_affine=True)\n",
      "Layer: block3, Module: Sequential(\n",
      "  (0): Block(\n",
      "    (norm1): LayerNorm((320,), eps=1e-06, elementwise_affine=True)\n",
      "    (attn): Attention(\n",
      "      (q): Linear(in_features=320, out_features=320, bias=True)\n",
      "      (kv): Linear(in_features=320, out_features=640, bias=True)\n",
      "      (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "      (proj): Linear(in_features=320, out_features=320, bias=True)\n",
      "      (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "      (sr): Conv2d(320, 320, kernel_size=(2, 2), stride=(2, 2))\n",
      "      (norm): LayerNorm((320,), eps=1e-05, elementwise_affine=True)\n",
      "    )\n",
      "    (drop_path): DropPath(drop_prob=0.018)\n",
      "    (norm2): LayerNorm((320,), eps=1e-06, elementwise_affine=True)\n",
      "    (mlp): Mlp(\n",
      "      (fc1): Linear(in_features=320, out_features=1280, bias=True)\n",
      "      (dwconv): DWConv(\n",
      "        (dwconv): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1280)\n",
      "      )\n",
      "      (act): GELU(approximate='none')\n",
      "      (fc2): Linear(in_features=1280, out_features=320, bias=True)\n",
      "      (drop): Dropout(p=0.0, inplace=False)\n",
      "    )\n",
      "  )\n",
      "  (1): Block(\n",
      "    (norm1): LayerNorm((320,), eps=1e-06, elementwise_affine=True)\n",
      "    (attn): Attention(\n",
      "      (q): Linear(in_features=320, out_features=320, bias=True)\n",
      "      (kv): Linear(in_features=320, out_features=640, bias=True)\n",
      "      (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "      (proj): Linear(in_features=320, out_features=320, bias=True)\n",
      "      (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "      (sr): Conv2d(320, 320, kernel_size=(2, 2), stride=(2, 2))\n",
      "      (norm): LayerNorm((320,), eps=1e-05, elementwise_affine=True)\n",
      "    )\n",
      "    (drop_path): DropPath(drop_prob=0.020)\n",
      "    (norm2): LayerNorm((320,), eps=1e-06, elementwise_affine=True)\n",
      "    (mlp): Mlp(\n",
      "      (fc1): Linear(in_features=320, out_features=1280, bias=True)\n",
      "      (dwconv): DWConv(\n",
      "        (dwconv): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1280)\n",
      "      )\n",
      "      (act): GELU(approximate='none')\n",
      "      (fc2): Linear(in_features=1280, out_features=320, bias=True)\n",
      "      (drop): Dropout(p=0.0, inplace=False)\n",
      "    )\n",
      "  )\n",
      "  (2): Block(\n",
      "    (norm1): LayerNorm((320,), eps=1e-06, elementwise_affine=True)\n",
      "    (attn): Attention(\n",
      "      (q): Linear(in_features=320, out_features=320, bias=True)\n",
      "      (kv): Linear(in_features=320, out_features=640, bias=True)\n",
      "      (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "      (proj): Linear(in_features=320, out_features=320, bias=True)\n",
      "      (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "      (sr): Conv2d(320, 320, kernel_size=(2, 2), stride=(2, 2))\n",
      "      (norm): LayerNorm((320,), eps=1e-05, elementwise_affine=True)\n",
      "    )\n",
      "    (drop_path): DropPath(drop_prob=0.022)\n",
      "    (norm2): LayerNorm((320,), eps=1e-06, elementwise_affine=True)\n",
      "    (mlp): Mlp(\n",
      "      (fc1): Linear(in_features=320, out_features=1280, bias=True)\n",
      "      (dwconv): DWConv(\n",
      "        (dwconv): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1280)\n",
      "      )\n",
      "      (act): GELU(approximate='none')\n",
      "      (fc2): Linear(in_features=1280, out_features=320, bias=True)\n",
      "      (drop): Dropout(p=0.0, inplace=False)\n",
      "    )\n",
      "  )\n",
      "  (3): Block(\n",
      "    (norm1): LayerNorm((320,), eps=1e-06, elementwise_affine=True)\n",
      "    (attn): Attention(\n",
      "      (q): Linear(in_features=320, out_features=320, bias=True)\n",
      "      (kv): Linear(in_features=320, out_features=640, bias=True)\n",
      "      (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "      (proj): Linear(in_features=320, out_features=320, bias=True)\n",
      "      (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "      (sr): Conv2d(320, 320, kernel_size=(2, 2), stride=(2, 2))\n",
      "      (norm): LayerNorm((320,), eps=1e-05, elementwise_affine=True)\n",
      "    )\n",
      "    (drop_path): DropPath(drop_prob=0.024)\n",
      "    (norm2): LayerNorm((320,), eps=1e-06, elementwise_affine=True)\n",
      "    (mlp): Mlp(\n",
      "      (fc1): Linear(in_features=320, out_features=1280, bias=True)\n",
      "      (dwconv): DWConv(\n",
      "        (dwconv): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1280)\n",
      "      )\n",
      "      (act): GELU(approximate='none')\n",
      "      (fc2): Linear(in_features=1280, out_features=320, bias=True)\n",
      "      (drop): Dropout(p=0.0, inplace=False)\n",
      "    )\n",
      "  )\n",
      "  (4): Block(\n",
      "    (norm1): LayerNorm((320,), eps=1e-06, elementwise_affine=True)\n",
      "    (attn): Attention(\n",
      "      (q): Linear(in_features=320, out_features=320, bias=True)\n",
      "      (kv): Linear(in_features=320, out_features=640, bias=True)\n",
      "      (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "      (proj): Linear(in_features=320, out_features=320, bias=True)\n",
      "      (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "      (sr): Conv2d(320, 320, kernel_size=(2, 2), stride=(2, 2))\n",
      "      (norm): LayerNorm((320,), eps=1e-05, elementwise_affine=True)\n",
      "    )\n",
      "    (drop_path): DropPath(drop_prob=0.025)\n",
      "    (norm2): LayerNorm((320,), eps=1e-06, elementwise_affine=True)\n",
      "    (mlp): Mlp(\n",
      "      (fc1): Linear(in_features=320, out_features=1280, bias=True)\n",
      "      (dwconv): DWConv(\n",
      "        (dwconv): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1280)\n",
      "      )\n",
      "      (act): GELU(approximate='none')\n",
      "      (fc2): Linear(in_features=1280, out_features=320, bias=True)\n",
      "      (drop): Dropout(p=0.0, inplace=False)\n",
      "    )\n",
      "  )\n",
      "  (5): Block(\n",
      "    (norm1): LayerNorm((320,), eps=1e-06, elementwise_affine=True)\n",
      "    (attn): Attention(\n",
      "      (q): Linear(in_features=320, out_features=320, bias=True)\n",
      "      (kv): Linear(in_features=320, out_features=640, bias=True)\n",
      "      (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "      (proj): Linear(in_features=320, out_features=320, bias=True)\n",
      "      (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "      (sr): Conv2d(320, 320, kernel_size=(2, 2), stride=(2, 2))\n",
      "      (norm): LayerNorm((320,), eps=1e-05, elementwise_affine=True)\n",
      "    )\n",
      "    (drop_path): DropPath(drop_prob=0.027)\n",
      "    (norm2): LayerNorm((320,), eps=1e-06, elementwise_affine=True)\n",
      "    (mlp): Mlp(\n",
      "      (fc1): Linear(in_features=320, out_features=1280, bias=True)\n",
      "      (dwconv): DWConv(\n",
      "        (dwconv): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1280)\n",
      "      )\n",
      "      (act): GELU(approximate='none')\n",
      "      (fc2): Linear(in_features=1280, out_features=320, bias=True)\n",
      "      (drop): Dropout(p=0.0, inplace=False)\n",
      "    )\n",
      "  )\n",
      "  (6): Block(\n",
      "    (norm1): LayerNorm((320,), eps=1e-06, elementwise_affine=True)\n",
      "    (attn): Attention(\n",
      "      (q): Linear(in_features=320, out_features=320, bias=True)\n",
      "      (kv): Linear(in_features=320, out_features=640, bias=True)\n",
      "      (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "      (proj): Linear(in_features=320, out_features=320, bias=True)\n",
      "      (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "      (sr): Conv2d(320, 320, kernel_size=(2, 2), stride=(2, 2))\n",
      "      (norm): LayerNorm((320,), eps=1e-05, elementwise_affine=True)\n",
      "    )\n",
      "    (drop_path): DropPath(drop_prob=0.029)\n",
      "    (norm2): LayerNorm((320,), eps=1e-06, elementwise_affine=True)\n",
      "    (mlp): Mlp(\n",
      "      (fc1): Linear(in_features=320, out_features=1280, bias=True)\n",
      "      (dwconv): DWConv(\n",
      "        (dwconv): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1280)\n",
      "      )\n",
      "      (act): GELU(approximate='none')\n",
      "      (fc2): Linear(in_features=1280, out_features=320, bias=True)\n",
      "      (drop): Dropout(p=0.0, inplace=False)\n",
      "    )\n",
      "  )\n",
      "  (7): Block(\n",
      "    (norm1): LayerNorm((320,), eps=1e-06, elementwise_affine=True)\n",
      "    (attn): Attention(\n",
      "      (q): Linear(in_features=320, out_features=320, bias=True)\n",
      "      (kv): Linear(in_features=320, out_features=640, bias=True)\n",
      "      (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "      (proj): Linear(in_features=320, out_features=320, bias=True)\n",
      "      (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "      (sr): Conv2d(320, 320, kernel_size=(2, 2), stride=(2, 2))\n",
      "      (norm): LayerNorm((320,), eps=1e-05, elementwise_affine=True)\n",
      "    )\n",
      "    (drop_path): DropPath(drop_prob=0.031)\n",
      "    (norm2): LayerNorm((320,), eps=1e-06, elementwise_affine=True)\n",
      "    (mlp): Mlp(\n",
      "      (fc1): Linear(in_features=320, out_features=1280, bias=True)\n",
      "      (dwconv): DWConv(\n",
      "        (dwconv): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1280)\n",
      "      )\n",
      "      (act): GELU(approximate='none')\n",
      "      (fc2): Linear(in_features=1280, out_features=320, bias=True)\n",
      "      (drop): Dropout(p=0.0, inplace=False)\n",
      "    )\n",
      "  )\n",
      "  (8): Block(\n",
      "    (norm1): LayerNorm((320,), eps=1e-06, elementwise_affine=True)\n",
      "    (attn): Attention(\n",
      "      (q): Linear(in_features=320, out_features=320, bias=True)\n",
      "      (kv): Linear(in_features=320, out_features=640, bias=True)\n",
      "      (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "      (proj): Linear(in_features=320, out_features=320, bias=True)\n",
      "      (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "      (sr): Conv2d(320, 320, kernel_size=(2, 2), stride=(2, 2))\n",
      "      (norm): LayerNorm((320,), eps=1e-05, elementwise_affine=True)\n",
      "    )\n",
      "    (drop_path): DropPath(drop_prob=0.033)\n",
      "    (norm2): LayerNorm((320,), eps=1e-06, elementwise_affine=True)\n",
      "    (mlp): Mlp(\n",
      "      (fc1): Linear(in_features=320, out_features=1280, bias=True)\n",
      "      (dwconv): DWConv(\n",
      "        (dwconv): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1280)\n",
      "      )\n",
      "      (act): GELU(approximate='none')\n",
      "      (fc2): Linear(in_features=1280, out_features=320, bias=True)\n",
      "      (drop): Dropout(p=0.0, inplace=False)\n",
      "    )\n",
      "  )\n",
      "  (9): Block(\n",
      "    (norm1): LayerNorm((320,), eps=1e-06, elementwise_affine=True)\n",
      "    (attn): Attention(\n",
      "      (q): Linear(in_features=320, out_features=320, bias=True)\n",
      "      (kv): Linear(in_features=320, out_features=640, bias=True)\n",
      "      (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "      (proj): Linear(in_features=320, out_features=320, bias=True)\n",
      "      (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "      (sr): Conv2d(320, 320, kernel_size=(2, 2), stride=(2, 2))\n",
      "      (norm): LayerNorm((320,), eps=1e-05, elementwise_affine=True)\n",
      "    )\n",
      "    (drop_path): DropPath(drop_prob=0.035)\n",
      "    (norm2): LayerNorm((320,), eps=1e-06, elementwise_affine=True)\n",
      "    (mlp): Mlp(\n",
      "      (fc1): Linear(in_features=320, out_features=1280, bias=True)\n",
      "      (dwconv): DWConv(\n",
      "        (dwconv): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1280)\n",
      "      )\n",
      "      (act): GELU(approximate='none')\n",
      "      (fc2): Linear(in_features=1280, out_features=320, bias=True)\n",
      "      (drop): Dropout(p=0.0, inplace=False)\n",
      "    )\n",
      "  )\n",
      "  (10): Block(\n",
      "    (norm1): LayerNorm((320,), eps=1e-06, elementwise_affine=True)\n",
      "    (attn): Attention(\n",
      "      (q): Linear(in_features=320, out_features=320, bias=True)\n",
      "      (kv): Linear(in_features=320, out_features=640, bias=True)\n",
      "      (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "      (proj): Linear(in_features=320, out_features=320, bias=True)\n",
      "      (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "      (sr): Conv2d(320, 320, kernel_size=(2, 2), stride=(2, 2))\n",
      "      (norm): LayerNorm((320,), eps=1e-05, elementwise_affine=True)\n",
      "    )\n",
      "    (drop_path): DropPath(drop_prob=0.037)\n",
      "    (norm2): LayerNorm((320,), eps=1e-06, elementwise_affine=True)\n",
      "    (mlp): Mlp(\n",
      "      (fc1): Linear(in_features=320, out_features=1280, bias=True)\n",
      "      (dwconv): DWConv(\n",
      "        (dwconv): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1280)\n",
      "      )\n",
      "      (act): GELU(approximate='none')\n",
      "      (fc2): Linear(in_features=1280, out_features=320, bias=True)\n",
      "      (drop): Dropout(p=0.0, inplace=False)\n",
      "    )\n",
      "  )\n",
      "  (11): Block(\n",
      "    (norm1): LayerNorm((320,), eps=1e-06, elementwise_affine=True)\n",
      "    (attn): Attention(\n",
      "      (q): Linear(in_features=320, out_features=320, bias=True)\n",
      "      (kv): Linear(in_features=320, out_features=640, bias=True)\n",
      "      (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "      (proj): Linear(in_features=320, out_features=320, bias=True)\n",
      "      (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "      (sr): Conv2d(320, 320, kernel_size=(2, 2), stride=(2, 2))\n",
      "      (norm): LayerNorm((320,), eps=1e-05, elementwise_affine=True)\n",
      "    )\n",
      "    (drop_path): DropPath(drop_prob=0.039)\n",
      "    (norm2): LayerNorm((320,), eps=1e-06, elementwise_affine=True)\n",
      "    (mlp): Mlp(\n",
      "      (fc1): Linear(in_features=320, out_features=1280, bias=True)\n",
      "      (dwconv): DWConv(\n",
      "        (dwconv): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1280)\n",
      "      )\n",
      "      (act): GELU(approximate='none')\n",
      "      (fc2): Linear(in_features=1280, out_features=320, bias=True)\n",
      "      (drop): Dropout(p=0.0, inplace=False)\n",
      "    )\n",
      "  )\n",
      "  (12): Block(\n",
      "    (norm1): LayerNorm((320,), eps=1e-06, elementwise_affine=True)\n",
      "    (attn): Attention(\n",
      "      (q): Linear(in_features=320, out_features=320, bias=True)\n",
      "      (kv): Linear(in_features=320, out_features=640, bias=True)\n",
      "      (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "      (proj): Linear(in_features=320, out_features=320, bias=True)\n",
      "      (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "      (sr): Conv2d(320, 320, kernel_size=(2, 2), stride=(2, 2))\n",
      "      (norm): LayerNorm((320,), eps=1e-05, elementwise_affine=True)\n",
      "    )\n",
      "    (drop_path): DropPath(drop_prob=0.041)\n",
      "    (norm2): LayerNorm((320,), eps=1e-06, elementwise_affine=True)\n",
      "    (mlp): Mlp(\n",
      "      (fc1): Linear(in_features=320, out_features=1280, bias=True)\n",
      "      (dwconv): DWConv(\n",
      "        (dwconv): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1280)\n",
      "      )\n",
      "      (act): GELU(approximate='none')\n",
      "      (fc2): Linear(in_features=1280, out_features=320, bias=True)\n",
      "      (drop): Dropout(p=0.0, inplace=False)\n",
      "    )\n",
      "  )\n",
      "  (13): Block(\n",
      "    (norm1): LayerNorm((320,), eps=1e-06, elementwise_affine=True)\n",
      "    (attn): Attention(\n",
      "      (q): Linear(in_features=320, out_features=320, bias=True)\n",
      "      (kv): Linear(in_features=320, out_features=640, bias=True)\n",
      "      (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "      (proj): Linear(in_features=320, out_features=320, bias=True)\n",
      "      (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "      (sr): Conv2d(320, 320, kernel_size=(2, 2), stride=(2, 2))\n",
      "      (norm): LayerNorm((320,), eps=1e-05, elementwise_affine=True)\n",
      "    )\n",
      "    (drop_path): DropPath(drop_prob=0.043)\n",
      "    (norm2): LayerNorm((320,), eps=1e-06, elementwise_affine=True)\n",
      "    (mlp): Mlp(\n",
      "      (fc1): Linear(in_features=320, out_features=1280, bias=True)\n",
      "      (dwconv): DWConv(\n",
      "        (dwconv): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1280)\n",
      "      )\n",
      "      (act): GELU(approximate='none')\n",
      "      (fc2): Linear(in_features=1280, out_features=320, bias=True)\n",
      "      (drop): Dropout(p=0.0, inplace=False)\n",
      "    )\n",
      "  )\n",
      "  (14): Block(\n",
      "    (norm1): LayerNorm((320,), eps=1e-06, elementwise_affine=True)\n",
      "    (attn): Attention(\n",
      "      (q): Linear(in_features=320, out_features=320, bias=True)\n",
      "      (kv): Linear(in_features=320, out_features=640, bias=True)\n",
      "      (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "      (proj): Linear(in_features=320, out_features=320, bias=True)\n",
      "      (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "      (sr): Conv2d(320, 320, kernel_size=(2, 2), stride=(2, 2))\n",
      "      (norm): LayerNorm((320,), eps=1e-05, elementwise_affine=True)\n",
      "    )\n",
      "    (drop_path): DropPath(drop_prob=0.045)\n",
      "    (norm2): LayerNorm((320,), eps=1e-06, elementwise_affine=True)\n",
      "    (mlp): Mlp(\n",
      "      (fc1): Linear(in_features=320, out_features=1280, bias=True)\n",
      "      (dwconv): DWConv(\n",
      "        (dwconv): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1280)\n",
      "      )\n",
      "      (act): GELU(approximate='none')\n",
      "      (fc2): Linear(in_features=1280, out_features=320, bias=True)\n",
      "      (drop): Dropout(p=0.0, inplace=False)\n",
      "    )\n",
      "  )\n",
      "  (15): Block(\n",
      "    (norm1): LayerNorm((320,), eps=1e-06, elementwise_affine=True)\n",
      "    (attn): Attention(\n",
      "      (q): Linear(in_features=320, out_features=320, bias=True)\n",
      "      (kv): Linear(in_features=320, out_features=640, bias=True)\n",
      "      (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "      (proj): Linear(in_features=320, out_features=320, bias=True)\n",
      "      (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "      (sr): Conv2d(320, 320, kernel_size=(2, 2), stride=(2, 2))\n",
      "      (norm): LayerNorm((320,), eps=1e-05, elementwise_affine=True)\n",
      "    )\n",
      "    (drop_path): DropPath(drop_prob=0.047)\n",
      "    (norm2): LayerNorm((320,), eps=1e-06, elementwise_affine=True)\n",
      "    (mlp): Mlp(\n",
      "      (fc1): Linear(in_features=320, out_features=1280, bias=True)\n",
      "      (dwconv): DWConv(\n",
      "        (dwconv): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1280)\n",
      "      )\n",
      "      (act): GELU(approximate='none')\n",
      "      (fc2): Linear(in_features=1280, out_features=320, bias=True)\n",
      "      (drop): Dropout(p=0.0, inplace=False)\n",
      "    )\n",
      "  )\n",
      "  (16): Block(\n",
      "    (norm1): LayerNorm((320,), eps=1e-06, elementwise_affine=True)\n",
      "    (attn): Attention(\n",
      "      (q): Linear(in_features=320, out_features=320, bias=True)\n",
      "      (kv): Linear(in_features=320, out_features=640, bias=True)\n",
      "      (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "      (proj): Linear(in_features=320, out_features=320, bias=True)\n",
      "      (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "      (sr): Conv2d(320, 320, kernel_size=(2, 2), stride=(2, 2))\n",
      "      (norm): LayerNorm((320,), eps=1e-05, elementwise_affine=True)\n",
      "    )\n",
      "    (drop_path): DropPath(drop_prob=0.049)\n",
      "    (norm2): LayerNorm((320,), eps=1e-06, elementwise_affine=True)\n",
      "    (mlp): Mlp(\n",
      "      (fc1): Linear(in_features=320, out_features=1280, bias=True)\n",
      "      (dwconv): DWConv(\n",
      "        (dwconv): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1280)\n",
      "      )\n",
      "      (act): GELU(approximate='none')\n",
      "      (fc2): Linear(in_features=1280, out_features=320, bias=True)\n",
      "      (drop): Dropout(p=0.0, inplace=False)\n",
      "    )\n",
      "  )\n",
      "  (17): Block(\n",
      "    (norm1): LayerNorm((320,), eps=1e-06, elementwise_affine=True)\n",
      "    (attn): Attention(\n",
      "      (q): Linear(in_features=320, out_features=320, bias=True)\n",
      "      (kv): Linear(in_features=320, out_features=640, bias=True)\n",
      "      (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "      (proj): Linear(in_features=320, out_features=320, bias=True)\n",
      "      (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "      (sr): Conv2d(320, 320, kernel_size=(2, 2), stride=(2, 2))\n",
      "      (norm): LayerNorm((320,), eps=1e-05, elementwise_affine=True)\n",
      "    )\n",
      "    (drop_path): DropPath(drop_prob=0.051)\n",
      "    (norm2): LayerNorm((320,), eps=1e-06, elementwise_affine=True)\n",
      "    (mlp): Mlp(\n",
      "      (fc1): Linear(in_features=320, out_features=1280, bias=True)\n",
      "      (dwconv): DWConv(\n",
      "        (dwconv): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1280)\n",
      "      )\n",
      "      (act): GELU(approximate='none')\n",
      "      (fc2): Linear(in_features=1280, out_features=320, bias=True)\n",
      "      (drop): Dropout(p=0.0, inplace=False)\n",
      "    )\n",
      "  )\n",
      "  (18): Block(\n",
      "    (norm1): LayerNorm((320,), eps=1e-06, elementwise_affine=True)\n",
      "    (attn): Attention(\n",
      "      (q): Linear(in_features=320, out_features=320, bias=True)\n",
      "      (kv): Linear(in_features=320, out_features=640, bias=True)\n",
      "      (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "      (proj): Linear(in_features=320, out_features=320, bias=True)\n",
      "      (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "      (sr): Conv2d(320, 320, kernel_size=(2, 2), stride=(2, 2))\n",
      "      (norm): LayerNorm((320,), eps=1e-05, elementwise_affine=True)\n",
      "    )\n",
      "    (drop_path): DropPath(drop_prob=0.053)\n",
      "    (norm2): LayerNorm((320,), eps=1e-06, elementwise_affine=True)\n",
      "    (mlp): Mlp(\n",
      "      (fc1): Linear(in_features=320, out_features=1280, bias=True)\n",
      "      (dwconv): DWConv(\n",
      "        (dwconv): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1280)\n",
      "      )\n",
      "      (act): GELU(approximate='none')\n",
      "      (fc2): Linear(in_features=1280, out_features=320, bias=True)\n",
      "      (drop): Dropout(p=0.0, inplace=False)\n",
      "    )\n",
      "  )\n",
      "  (19): Block(\n",
      "    (norm1): LayerNorm((320,), eps=1e-06, elementwise_affine=True)\n",
      "    (attn): Attention(\n",
      "      (q): Linear(in_features=320, out_features=320, bias=True)\n",
      "      (kv): Linear(in_features=320, out_features=640, bias=True)\n",
      "      (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "      (proj): Linear(in_features=320, out_features=320, bias=True)\n",
      "      (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "      (sr): Conv2d(320, 320, kernel_size=(2, 2), stride=(2, 2))\n",
      "      (norm): LayerNorm((320,), eps=1e-05, elementwise_affine=True)\n",
      "    )\n",
      "    (drop_path): DropPath(drop_prob=0.055)\n",
      "    (norm2): LayerNorm((320,), eps=1e-06, elementwise_affine=True)\n",
      "    (mlp): Mlp(\n",
      "      (fc1): Linear(in_features=320, out_features=1280, bias=True)\n",
      "      (dwconv): DWConv(\n",
      "        (dwconv): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1280)\n",
      "      )\n",
      "      (act): GELU(approximate='none')\n",
      "      (fc2): Linear(in_features=1280, out_features=320, bias=True)\n",
      "      (drop): Dropout(p=0.0, inplace=False)\n",
      "    )\n",
      "  )\n",
      "  (20): Block(\n",
      "    (norm1): LayerNorm((320,), eps=1e-06, elementwise_affine=True)\n",
      "    (attn): Attention(\n",
      "      (q): Linear(in_features=320, out_features=320, bias=True)\n",
      "      (kv): Linear(in_features=320, out_features=640, bias=True)\n",
      "      (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "      (proj): Linear(in_features=320, out_features=320, bias=True)\n",
      "      (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "      (sr): Conv2d(320, 320, kernel_size=(2, 2), stride=(2, 2))\n",
      "      (norm): LayerNorm((320,), eps=1e-05, elementwise_affine=True)\n",
      "    )\n",
      "    (drop_path): DropPath(drop_prob=0.057)\n",
      "    (norm2): LayerNorm((320,), eps=1e-06, elementwise_affine=True)\n",
      "    (mlp): Mlp(\n",
      "      (fc1): Linear(in_features=320, out_features=1280, bias=True)\n",
      "      (dwconv): DWConv(\n",
      "        (dwconv): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1280)\n",
      "      )\n",
      "      (act): GELU(approximate='none')\n",
      "      (fc2): Linear(in_features=1280, out_features=320, bias=True)\n",
      "      (drop): Dropout(p=0.0, inplace=False)\n",
      "    )\n",
      "  )\n",
      "  (21): Block(\n",
      "    (norm1): LayerNorm((320,), eps=1e-06, elementwise_affine=True)\n",
      "    (attn): Attention(\n",
      "      (q): Linear(in_features=320, out_features=320, bias=True)\n",
      "      (kv): Linear(in_features=320, out_features=640, bias=True)\n",
      "      (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "      (proj): Linear(in_features=320, out_features=320, bias=True)\n",
      "      (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "      (sr): Conv2d(320, 320, kernel_size=(2, 2), stride=(2, 2))\n",
      "      (norm): LayerNorm((320,), eps=1e-05, elementwise_affine=True)\n",
      "    )\n",
      "    (drop_path): DropPath(drop_prob=0.059)\n",
      "    (norm2): LayerNorm((320,), eps=1e-06, elementwise_affine=True)\n",
      "    (mlp): Mlp(\n",
      "      (fc1): Linear(in_features=320, out_features=1280, bias=True)\n",
      "      (dwconv): DWConv(\n",
      "        (dwconv): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1280)\n",
      "      )\n",
      "      (act): GELU(approximate='none')\n",
      "      (fc2): Linear(in_features=1280, out_features=320, bias=True)\n",
      "      (drop): Dropout(p=0.0, inplace=False)\n",
      "    )\n",
      "  )\n",
      "  (22): Block(\n",
      "    (norm1): LayerNorm((320,), eps=1e-06, elementwise_affine=True)\n",
      "    (attn): Attention(\n",
      "      (q): Linear(in_features=320, out_features=320, bias=True)\n",
      "      (kv): Linear(in_features=320, out_features=640, bias=True)\n",
      "      (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "      (proj): Linear(in_features=320, out_features=320, bias=True)\n",
      "      (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "      (sr): Conv2d(320, 320, kernel_size=(2, 2), stride=(2, 2))\n",
      "      (norm): LayerNorm((320,), eps=1e-05, elementwise_affine=True)\n",
      "    )\n",
      "    (drop_path): DropPath(drop_prob=0.061)\n",
      "    (norm2): LayerNorm((320,), eps=1e-06, elementwise_affine=True)\n",
      "    (mlp): Mlp(\n",
      "      (fc1): Linear(in_features=320, out_features=1280, bias=True)\n",
      "      (dwconv): DWConv(\n",
      "        (dwconv): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1280)\n",
      "      )\n",
      "      (act): GELU(approximate='none')\n",
      "      (fc2): Linear(in_features=1280, out_features=320, bias=True)\n",
      "      (drop): Dropout(p=0.0, inplace=False)\n",
      "    )\n",
      "  )\n",
      "  (23): Block(\n",
      "    (norm1): LayerNorm((320,), eps=1e-06, elementwise_affine=True)\n",
      "    (attn): Attention(\n",
      "      (q): Linear(in_features=320, out_features=320, bias=True)\n",
      "      (kv): Linear(in_features=320, out_features=640, bias=True)\n",
      "      (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "      (proj): Linear(in_features=320, out_features=320, bias=True)\n",
      "      (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "      (sr): Conv2d(320, 320, kernel_size=(2, 2), stride=(2, 2))\n",
      "      (norm): LayerNorm((320,), eps=1e-05, elementwise_affine=True)\n",
      "    )\n",
      "    (drop_path): DropPath(drop_prob=0.063)\n",
      "    (norm2): LayerNorm((320,), eps=1e-06, elementwise_affine=True)\n",
      "    (mlp): Mlp(\n",
      "      (fc1): Linear(in_features=320, out_features=1280, bias=True)\n",
      "      (dwconv): DWConv(\n",
      "        (dwconv): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1280)\n",
      "      )\n",
      "      (act): GELU(approximate='none')\n",
      "      (fc2): Linear(in_features=1280, out_features=320, bias=True)\n",
      "      (drop): Dropout(p=0.0, inplace=False)\n",
      "    )\n",
      "  )\n",
      "  (24): Block(\n",
      "    (norm1): LayerNorm((320,), eps=1e-06, elementwise_affine=True)\n",
      "    (attn): Attention(\n",
      "      (q): Linear(in_features=320, out_features=320, bias=True)\n",
      "      (kv): Linear(in_features=320, out_features=640, bias=True)\n",
      "      (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "      (proj): Linear(in_features=320, out_features=320, bias=True)\n",
      "      (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "      (sr): Conv2d(320, 320, kernel_size=(2, 2), stride=(2, 2))\n",
      "      (norm): LayerNorm((320,), eps=1e-05, elementwise_affine=True)\n",
      "    )\n",
      "    (drop_path): DropPath(drop_prob=0.065)\n",
      "    (norm2): LayerNorm((320,), eps=1e-06, elementwise_affine=True)\n",
      "    (mlp): Mlp(\n",
      "      (fc1): Linear(in_features=320, out_features=1280, bias=True)\n",
      "      (dwconv): DWConv(\n",
      "        (dwconv): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1280)\n",
      "      )\n",
      "      (act): GELU(approximate='none')\n",
      "      (fc2): Linear(in_features=1280, out_features=320, bias=True)\n",
      "      (drop): Dropout(p=0.0, inplace=False)\n",
      "    )\n",
      "  )\n",
      "  (25): Block(\n",
      "    (norm1): LayerNorm((320,), eps=1e-06, elementwise_affine=True)\n",
      "    (attn): Attention(\n",
      "      (q): Linear(in_features=320, out_features=320, bias=True)\n",
      "      (kv): Linear(in_features=320, out_features=640, bias=True)\n",
      "      (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "      (proj): Linear(in_features=320, out_features=320, bias=True)\n",
      "      (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "      (sr): Conv2d(320, 320, kernel_size=(2, 2), stride=(2, 2))\n",
      "      (norm): LayerNorm((320,), eps=1e-05, elementwise_affine=True)\n",
      "    )\n",
      "    (drop_path): DropPath(drop_prob=0.067)\n",
      "    (norm2): LayerNorm((320,), eps=1e-06, elementwise_affine=True)\n",
      "    (mlp): Mlp(\n",
      "      (fc1): Linear(in_features=320, out_features=1280, bias=True)\n",
      "      (dwconv): DWConv(\n",
      "        (dwconv): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1280)\n",
      "      )\n",
      "      (act): GELU(approximate='none')\n",
      "      (fc2): Linear(in_features=1280, out_features=320, bias=True)\n",
      "      (drop): Dropout(p=0.0, inplace=False)\n",
      "    )\n",
      "  )\n",
      "  (26): Block(\n",
      "    (norm1): LayerNorm((320,), eps=1e-06, elementwise_affine=True)\n",
      "    (attn): Attention(\n",
      "      (q): Linear(in_features=320, out_features=320, bias=True)\n",
      "      (kv): Linear(in_features=320, out_features=640, bias=True)\n",
      "      (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "      (proj): Linear(in_features=320, out_features=320, bias=True)\n",
      "      (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "      (sr): Conv2d(320, 320, kernel_size=(2, 2), stride=(2, 2))\n",
      "      (norm): LayerNorm((320,), eps=1e-05, elementwise_affine=True)\n",
      "    )\n",
      "    (drop_path): DropPath(drop_prob=0.069)\n",
      "    (norm2): LayerNorm((320,), eps=1e-06, elementwise_affine=True)\n",
      "    (mlp): Mlp(\n",
      "      (fc1): Linear(in_features=320, out_features=1280, bias=True)\n",
      "      (dwconv): DWConv(\n",
      "        (dwconv): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1280)\n",
      "      )\n",
      "      (act): GELU(approximate='none')\n",
      "      (fc2): Linear(in_features=1280, out_features=320, bias=True)\n",
      "      (drop): Dropout(p=0.0, inplace=False)\n",
      "    )\n",
      "  )\n",
      "  (27): Block(\n",
      "    (norm1): LayerNorm((320,), eps=1e-06, elementwise_affine=True)\n",
      "    (attn): Attention(\n",
      "      (q): Linear(in_features=320, out_features=320, bias=True)\n",
      "      (kv): Linear(in_features=320, out_features=640, bias=True)\n",
      "      (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "      (proj): Linear(in_features=320, out_features=320, bias=True)\n",
      "      (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "      (sr): Conv2d(320, 320, kernel_size=(2, 2), stride=(2, 2))\n",
      "      (norm): LayerNorm((320,), eps=1e-05, elementwise_affine=True)\n",
      "    )\n",
      "    (drop_path): DropPath(drop_prob=0.071)\n",
      "    (norm2): LayerNorm((320,), eps=1e-06, elementwise_affine=True)\n",
      "    (mlp): Mlp(\n",
      "      (fc1): Linear(in_features=320, out_features=1280, bias=True)\n",
      "      (dwconv): DWConv(\n",
      "        (dwconv): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1280)\n",
      "      )\n",
      "      (act): GELU(approximate='none')\n",
      "      (fc2): Linear(in_features=1280, out_features=320, bias=True)\n",
      "      (drop): Dropout(p=0.0, inplace=False)\n",
      "    )\n",
      "  )\n",
      "  (28): Block(\n",
      "    (norm1): LayerNorm((320,), eps=1e-06, elementwise_affine=True)\n",
      "    (attn): Attention(\n",
      "      (q): Linear(in_features=320, out_features=320, bias=True)\n",
      "      (kv): Linear(in_features=320, out_features=640, bias=True)\n",
      "      (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "      (proj): Linear(in_features=320, out_features=320, bias=True)\n",
      "      (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "      (sr): Conv2d(320, 320, kernel_size=(2, 2), stride=(2, 2))\n",
      "      (norm): LayerNorm((320,), eps=1e-05, elementwise_affine=True)\n",
      "    )\n",
      "    (drop_path): DropPath(drop_prob=0.073)\n",
      "    (norm2): LayerNorm((320,), eps=1e-06, elementwise_affine=True)\n",
      "    (mlp): Mlp(\n",
      "      (fc1): Linear(in_features=320, out_features=1280, bias=True)\n",
      "      (dwconv): DWConv(\n",
      "        (dwconv): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1280)\n",
      "      )\n",
      "      (act): GELU(approximate='none')\n",
      "      (fc2): Linear(in_features=1280, out_features=320, bias=True)\n",
      "      (drop): Dropout(p=0.0, inplace=False)\n",
      "    )\n",
      "  )\n",
      "  (29): Block(\n",
      "    (norm1): LayerNorm((320,), eps=1e-06, elementwise_affine=True)\n",
      "    (attn): Attention(\n",
      "      (q): Linear(in_features=320, out_features=320, bias=True)\n",
      "      (kv): Linear(in_features=320, out_features=640, bias=True)\n",
      "      (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "      (proj): Linear(in_features=320, out_features=320, bias=True)\n",
      "      (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "      (sr): Conv2d(320, 320, kernel_size=(2, 2), stride=(2, 2))\n",
      "      (norm): LayerNorm((320,), eps=1e-05, elementwise_affine=True)\n",
      "    )\n",
      "    (drop_path): DropPath(drop_prob=0.075)\n",
      "    (norm2): LayerNorm((320,), eps=1e-06, elementwise_affine=True)\n",
      "    (mlp): Mlp(\n",
      "      (fc1): Linear(in_features=320, out_features=1280, bias=True)\n",
      "      (dwconv): DWConv(\n",
      "        (dwconv): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1280)\n",
      "      )\n",
      "      (act): GELU(approximate='none')\n",
      "      (fc2): Linear(in_features=1280, out_features=320, bias=True)\n",
      "      (drop): Dropout(p=0.0, inplace=False)\n",
      "    )\n",
      "  )\n",
      "  (30): Block(\n",
      "    (norm1): LayerNorm((320,), eps=1e-06, elementwise_affine=True)\n",
      "    (attn): Attention(\n",
      "      (q): Linear(in_features=320, out_features=320, bias=True)\n",
      "      (kv): Linear(in_features=320, out_features=640, bias=True)\n",
      "      (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "      (proj): Linear(in_features=320, out_features=320, bias=True)\n",
      "      (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "      (sr): Conv2d(320, 320, kernel_size=(2, 2), stride=(2, 2))\n",
      "      (norm): LayerNorm((320,), eps=1e-05, elementwise_affine=True)\n",
      "    )\n",
      "    (drop_path): DropPath(drop_prob=0.076)\n",
      "    (norm2): LayerNorm((320,), eps=1e-06, elementwise_affine=True)\n",
      "    (mlp): Mlp(\n",
      "      (fc1): Linear(in_features=320, out_features=1280, bias=True)\n",
      "      (dwconv): DWConv(\n",
      "        (dwconv): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1280)\n",
      "      )\n",
      "      (act): GELU(approximate='none')\n",
      "      (fc2): Linear(in_features=1280, out_features=320, bias=True)\n",
      "      (drop): Dropout(p=0.0, inplace=False)\n",
      "    )\n",
      "  )\n",
      "  (31): Block(\n",
      "    (norm1): LayerNorm((320,), eps=1e-06, elementwise_affine=True)\n",
      "    (attn): Attention(\n",
      "      (q): Linear(in_features=320, out_features=320, bias=True)\n",
      "      (kv): Linear(in_features=320, out_features=640, bias=True)\n",
      "      (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "      (proj): Linear(in_features=320, out_features=320, bias=True)\n",
      "      (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "      (sr): Conv2d(320, 320, kernel_size=(2, 2), stride=(2, 2))\n",
      "      (norm): LayerNorm((320,), eps=1e-05, elementwise_affine=True)\n",
      "    )\n",
      "    (drop_path): DropPath(drop_prob=0.078)\n",
      "    (norm2): LayerNorm((320,), eps=1e-06, elementwise_affine=True)\n",
      "    (mlp): Mlp(\n",
      "      (fc1): Linear(in_features=320, out_features=1280, bias=True)\n",
      "      (dwconv): DWConv(\n",
      "        (dwconv): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1280)\n",
      "      )\n",
      "      (act): GELU(approximate='none')\n",
      "      (fc2): Linear(in_features=1280, out_features=320, bias=True)\n",
      "      (drop): Dropout(p=0.0, inplace=False)\n",
      "    )\n",
      "  )\n",
      "  (32): Block(\n",
      "    (norm1): LayerNorm((320,), eps=1e-06, elementwise_affine=True)\n",
      "    (attn): Attention(\n",
      "      (q): Linear(in_features=320, out_features=320, bias=True)\n",
      "      (kv): Linear(in_features=320, out_features=640, bias=True)\n",
      "      (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "      (proj): Linear(in_features=320, out_features=320, bias=True)\n",
      "      (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "      (sr): Conv2d(320, 320, kernel_size=(2, 2), stride=(2, 2))\n",
      "      (norm): LayerNorm((320,), eps=1e-05, elementwise_affine=True)\n",
      "    )\n",
      "    (drop_path): DropPath(drop_prob=0.080)\n",
      "    (norm2): LayerNorm((320,), eps=1e-06, elementwise_affine=True)\n",
      "    (mlp): Mlp(\n",
      "      (fc1): Linear(in_features=320, out_features=1280, bias=True)\n",
      "      (dwconv): DWConv(\n",
      "        (dwconv): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1280)\n",
      "      )\n",
      "      (act): GELU(approximate='none')\n",
      "      (fc2): Linear(in_features=1280, out_features=320, bias=True)\n",
      "      (drop): Dropout(p=0.0, inplace=False)\n",
      "    )\n",
      "  )\n",
      "  (33): Block(\n",
      "    (norm1): LayerNorm((320,), eps=1e-06, elementwise_affine=True)\n",
      "    (attn): Attention(\n",
      "      (q): Linear(in_features=320, out_features=320, bias=True)\n",
      "      (kv): Linear(in_features=320, out_features=640, bias=True)\n",
      "      (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "      (proj): Linear(in_features=320, out_features=320, bias=True)\n",
      "      (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "      (sr): Conv2d(320, 320, kernel_size=(2, 2), stride=(2, 2))\n",
      "      (norm): LayerNorm((320,), eps=1e-05, elementwise_affine=True)\n",
      "    )\n",
      "    (drop_path): DropPath(drop_prob=0.082)\n",
      "    (norm2): LayerNorm((320,), eps=1e-06, elementwise_affine=True)\n",
      "    (mlp): Mlp(\n",
      "      (fc1): Linear(in_features=320, out_features=1280, bias=True)\n",
      "      (dwconv): DWConv(\n",
      "        (dwconv): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1280)\n",
      "      )\n",
      "      (act): GELU(approximate='none')\n",
      "      (fc2): Linear(in_features=1280, out_features=320, bias=True)\n",
      "      (drop): Dropout(p=0.0, inplace=False)\n",
      "    )\n",
      "  )\n",
      "  (34): Block(\n",
      "    (norm1): LayerNorm((320,), eps=1e-06, elementwise_affine=True)\n",
      "    (attn): Attention(\n",
      "      (q): Linear(in_features=320, out_features=320, bias=True)\n",
      "      (kv): Linear(in_features=320, out_features=640, bias=True)\n",
      "      (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "      (proj): Linear(in_features=320, out_features=320, bias=True)\n",
      "      (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "      (sr): Conv2d(320, 320, kernel_size=(2, 2), stride=(2, 2))\n",
      "      (norm): LayerNorm((320,), eps=1e-05, elementwise_affine=True)\n",
      "    )\n",
      "    (drop_path): DropPath(drop_prob=0.084)\n",
      "    (norm2): LayerNorm((320,), eps=1e-06, elementwise_affine=True)\n",
      "    (mlp): Mlp(\n",
      "      (fc1): Linear(in_features=320, out_features=1280, bias=True)\n",
      "      (dwconv): DWConv(\n",
      "        (dwconv): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1280)\n",
      "      )\n",
      "      (act): GELU(approximate='none')\n",
      "      (fc2): Linear(in_features=1280, out_features=320, bias=True)\n",
      "      (drop): Dropout(p=0.0, inplace=False)\n",
      "    )\n",
      "  )\n",
      "  (35): Block(\n",
      "    (norm1): LayerNorm((320,), eps=1e-06, elementwise_affine=True)\n",
      "    (attn): Attention(\n",
      "      (q): Linear(in_features=320, out_features=320, bias=True)\n",
      "      (kv): Linear(in_features=320, out_features=640, bias=True)\n",
      "      (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "      (proj): Linear(in_features=320, out_features=320, bias=True)\n",
      "      (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "      (sr): Conv2d(320, 320, kernel_size=(2, 2), stride=(2, 2))\n",
      "      (norm): LayerNorm((320,), eps=1e-05, elementwise_affine=True)\n",
      "    )\n",
      "    (drop_path): DropPath(drop_prob=0.086)\n",
      "    (norm2): LayerNorm((320,), eps=1e-06, elementwise_affine=True)\n",
      "    (mlp): Mlp(\n",
      "      (fc1): Linear(in_features=320, out_features=1280, bias=True)\n",
      "      (dwconv): DWConv(\n",
      "        (dwconv): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1280)\n",
      "      )\n",
      "      (act): GELU(approximate='none')\n",
      "      (fc2): Linear(in_features=1280, out_features=320, bias=True)\n",
      "      (drop): Dropout(p=0.0, inplace=False)\n",
      "    )\n",
      "  )\n",
      "  (36): Block(\n",
      "    (norm1): LayerNorm((320,), eps=1e-06, elementwise_affine=True)\n",
      "    (attn): Attention(\n",
      "      (q): Linear(in_features=320, out_features=320, bias=True)\n",
      "      (kv): Linear(in_features=320, out_features=640, bias=True)\n",
      "      (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "      (proj): Linear(in_features=320, out_features=320, bias=True)\n",
      "      (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "      (sr): Conv2d(320, 320, kernel_size=(2, 2), stride=(2, 2))\n",
      "      (norm): LayerNorm((320,), eps=1e-05, elementwise_affine=True)\n",
      "    )\n",
      "    (drop_path): DropPath(drop_prob=0.088)\n",
      "    (norm2): LayerNorm((320,), eps=1e-06, elementwise_affine=True)\n",
      "    (mlp): Mlp(\n",
      "      (fc1): Linear(in_features=320, out_features=1280, bias=True)\n",
      "      (dwconv): DWConv(\n",
      "        (dwconv): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1280)\n",
      "      )\n",
      "      (act): GELU(approximate='none')\n",
      "      (fc2): Linear(in_features=1280, out_features=320, bias=True)\n",
      "      (drop): Dropout(p=0.0, inplace=False)\n",
      "    )\n",
      "  )\n",
      "  (37): Block(\n",
      "    (norm1): LayerNorm((320,), eps=1e-06, elementwise_affine=True)\n",
      "    (attn): Attention(\n",
      "      (q): Linear(in_features=320, out_features=320, bias=True)\n",
      "      (kv): Linear(in_features=320, out_features=640, bias=True)\n",
      "      (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "      (proj): Linear(in_features=320, out_features=320, bias=True)\n",
      "      (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "      (sr): Conv2d(320, 320, kernel_size=(2, 2), stride=(2, 2))\n",
      "      (norm): LayerNorm((320,), eps=1e-05, elementwise_affine=True)\n",
      "    )\n",
      "    (drop_path): DropPath(drop_prob=0.090)\n",
      "    (norm2): LayerNorm((320,), eps=1e-06, elementwise_affine=True)\n",
      "    (mlp): Mlp(\n",
      "      (fc1): Linear(in_features=320, out_features=1280, bias=True)\n",
      "      (dwconv): DWConv(\n",
      "        (dwconv): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1280)\n",
      "      )\n",
      "      (act): GELU(approximate='none')\n",
      "      (fc2): Linear(in_features=1280, out_features=320, bias=True)\n",
      "      (drop): Dropout(p=0.0, inplace=False)\n",
      "    )\n",
      "  )\n",
      "  (38): Block(\n",
      "    (norm1): LayerNorm((320,), eps=1e-06, elementwise_affine=True)\n",
      "    (attn): Attention(\n",
      "      (q): Linear(in_features=320, out_features=320, bias=True)\n",
      "      (kv): Linear(in_features=320, out_features=640, bias=True)\n",
      "      (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "      (proj): Linear(in_features=320, out_features=320, bias=True)\n",
      "      (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "      (sr): Conv2d(320, 320, kernel_size=(2, 2), stride=(2, 2))\n",
      "      (norm): LayerNorm((320,), eps=1e-05, elementwise_affine=True)\n",
      "    )\n",
      "    (drop_path): DropPath(drop_prob=0.092)\n",
      "    (norm2): LayerNorm((320,), eps=1e-06, elementwise_affine=True)\n",
      "    (mlp): Mlp(\n",
      "      (fc1): Linear(in_features=320, out_features=1280, bias=True)\n",
      "      (dwconv): DWConv(\n",
      "        (dwconv): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1280)\n",
      "      )\n",
      "      (act): GELU(approximate='none')\n",
      "      (fc2): Linear(in_features=1280, out_features=320, bias=True)\n",
      "      (drop): Dropout(p=0.0, inplace=False)\n",
      "    )\n",
      "  )\n",
      "  (39): Block(\n",
      "    (norm1): LayerNorm((320,), eps=1e-06, elementwise_affine=True)\n",
      "    (attn): Attention(\n",
      "      (q): Linear(in_features=320, out_features=320, bias=True)\n",
      "      (kv): Linear(in_features=320, out_features=640, bias=True)\n",
      "      (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "      (proj): Linear(in_features=320, out_features=320, bias=True)\n",
      "      (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "      (sr): Conv2d(320, 320, kernel_size=(2, 2), stride=(2, 2))\n",
      "      (norm): LayerNorm((320,), eps=1e-05, elementwise_affine=True)\n",
      "    )\n",
      "    (drop_path): DropPath(drop_prob=0.094)\n",
      "    (norm2): LayerNorm((320,), eps=1e-06, elementwise_affine=True)\n",
      "    (mlp): Mlp(\n",
      "      (fc1): Linear(in_features=320, out_features=1280, bias=True)\n",
      "      (dwconv): DWConv(\n",
      "        (dwconv): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1280)\n",
      "      )\n",
      "      (act): GELU(approximate='none')\n",
      "      (fc2): Linear(in_features=1280, out_features=320, bias=True)\n",
      "      (drop): Dropout(p=0.0, inplace=False)\n",
      "    )\n",
      "  )\n",
      ")\n",
      "Layer: norm3, Module: LayerNorm((320,), eps=1e-06, elementwise_affine=True)\n",
      "Layer: block4, Module: Sequential(\n",
      "  (0): Block(\n",
      "    (norm1): LayerNorm((512,), eps=1e-06, elementwise_affine=True)\n",
      "    (attn): Attention(\n",
      "      (q): Linear(in_features=512, out_features=512, bias=True)\n",
      "      (kv): Linear(in_features=512, out_features=1024, bias=True)\n",
      "      (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "      (proj): Linear(in_features=512, out_features=512, bias=True)\n",
      "      (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "      (sr): Identity()\n",
      "      (norm): Identity()\n",
      "    )\n",
      "    (drop_path): DropPath(drop_prob=0.096)\n",
      "    (norm2): LayerNorm((512,), eps=1e-06, elementwise_affine=True)\n",
      "    (mlp): Mlp(\n",
      "      (fc1): Linear(in_features=512, out_features=2048, bias=True)\n",
      "      (dwconv): DWConv(\n",
      "        (dwconv): Conv2d(2048, 2048, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2048)\n",
      "      )\n",
      "      (act): GELU(approximate='none')\n",
      "      (fc2): Linear(in_features=2048, out_features=512, bias=True)\n",
      "      (drop): Dropout(p=0.0, inplace=False)\n",
      "    )\n",
      "  )\n",
      "  (1): Block(\n",
      "    (norm1): LayerNorm((512,), eps=1e-06, elementwise_affine=True)\n",
      "    (attn): Attention(\n",
      "      (q): Linear(in_features=512, out_features=512, bias=True)\n",
      "      (kv): Linear(in_features=512, out_features=1024, bias=True)\n",
      "      (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "      (proj): Linear(in_features=512, out_features=512, bias=True)\n",
      "      (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "      (sr): Identity()\n",
      "      (norm): Identity()\n",
      "    )\n",
      "    (drop_path): DropPath(drop_prob=0.098)\n",
      "    (norm2): LayerNorm((512,), eps=1e-06, elementwise_affine=True)\n",
      "    (mlp): Mlp(\n",
      "      (fc1): Linear(in_features=512, out_features=2048, bias=True)\n",
      "      (dwconv): DWConv(\n",
      "        (dwconv): Conv2d(2048, 2048, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2048)\n",
      "      )\n",
      "      (act): GELU(approximate='none')\n",
      "      (fc2): Linear(in_features=2048, out_features=512, bias=True)\n",
      "      (drop): Dropout(p=0.0, inplace=False)\n",
      "    )\n",
      "  )\n",
      "  (2): Block(\n",
      "    (norm1): LayerNorm((512,), eps=1e-06, elementwise_affine=True)\n",
      "    (attn): Attention(\n",
      "      (q): Linear(in_features=512, out_features=512, bias=True)\n",
      "      (kv): Linear(in_features=512, out_features=1024, bias=True)\n",
      "      (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "      (proj): Linear(in_features=512, out_features=512, bias=True)\n",
      "      (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "      (sr): Identity()\n",
      "      (norm): Identity()\n",
      "    )\n",
      "    (drop_path): DropPath(drop_prob=0.100)\n",
      "    (norm2): LayerNorm((512,), eps=1e-06, elementwise_affine=True)\n",
      "    (mlp): Mlp(\n",
      "      (fc1): Linear(in_features=512, out_features=2048, bias=True)\n",
      "      (dwconv): DWConv(\n",
      "        (dwconv): Conv2d(2048, 2048, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2048)\n",
      "      )\n",
      "      (act): GELU(approximate='none')\n",
      "      (fc2): Linear(in_features=2048, out_features=512, bias=True)\n",
      "      (drop): Dropout(p=0.0, inplace=False)\n",
      "    )\n",
      "  )\n",
      ")\n",
      "Layer: norm4, Module: LayerNorm((512,), eps=1e-06, elementwise_affine=True)\n",
      "\n",
      "Encoder Layer Names:['patch_embed1', 'patch_embed2', 'patch_embed3', 'patch_embed4', 'block1', 'norm1', 'block2', 'norm2', 'block3', 'norm3', 'block4', 'norm4']\n"
     ]
    }
   ],
   "source": [
    "model = SMPLitModule(\n",
    "    arch=ARCH,\n",
    "    encoder_name=ENCODER_NAME,\n",
    "    encoder_weights=\"imagenet\",\n",
    "    in_channels=data_module.in_channels,\n",
    "    out_classes=1,  # Binary segmentation\n",
    "    loss1=LOSS1,\n",
    "    loss2=LOSS2,\n",
    "    lr=1e-3,\n",
    "    use_scheduler=False\n",
    ")\n",
    "\n",
    "layer_names = []\n",
    "for name, module in model.model.encoder.named_children():\n",
    "    print(f\"Layer: {name}, Module: {module}\")\n",
    "    layer_names.append(name)\n",
    "\n",
    "print(\"\\nEncoder Layer Names:\" + str(layer_names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "013794a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# freeze_tool = FreezeSMPEncoderUtils()\n",
    "# freeze_tool(model, ENCODER_NAME, layers_range=(1, 2))  # Freeze the 2nd layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8744c046",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " Tip: For seamless cloud uploads and versioning, try installing [litmodels](https://pypi.org/project/litmodels/) to enable LitModelCheckpoint, which syncs automatically with the Lightning model registry.\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    }
   ],
   "source": [
    "trainer = L.Trainer(\n",
    "    log_every_n_steps=5\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "497bc6a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/leo/apps/miniconda3/envs/CVers/lib/python3.11/site-packages/lightning/pytorch/loops/utilities.py:73: `max_epochs` was not set. Setting it to 1000 epochs. To train without an epoch limit, set `max_epochs=-1`.\n",
      "You are using a CUDA device ('NVIDIA GeForce RTX 3090') that has Tensor Cores. To properly utilize them, you should set `torch.set_float32_matmul_precision('medium' | 'high')` which will trade-off precision for performance. For more details, read https://pytorch.org/docs/stable/generated/torch.set_float32_matmul_precision.html#torch.set_float32_matmul_precision\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008000; text-decoration-color: #008000\">Using existing split: ../data_splits/data_split_42_70_10.csv</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[32mUsing existing split: ..\u001b[0m\u001b[32m/data_splits/\u001b[0m\u001b[32mdata_split_42_70_10.csv\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "88c4075cff7840b0a0dd863d9f03b8c8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Finding best initial lr:   0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_steps=100` reached.\n",
      "Learning rate set to 0.002089296130854039\n",
      "Restoring states from the checkpoint path at /home/leo/unsw/comp9517/CV9517_Group-Project/notebooks/.lr_find_5bac34d6-58b7-4c92-80ab-1fc0fce3e67e.ckpt\n",
      "Restored all states from the checkpoint at /home/leo/unsw/comp9517/CV9517_Group-Project/notebooks/.lr_find_5bac34d6-58b7-4c92-80ab-1fc0fce3e67e.ckpt\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #000080; text-decoration-color: #000080\">Teardown called, cleaning up datasets...</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[34mTeardown called, cleaning up datasets\u001b[0m\u001b[34m...\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_842785/1558274056.py:6: UserWarning: FigureCanvasAgg is non-interactive, and thus cannot be shown\n",
      "  fig.show()\n"
     ]
    }
   ],
   "source": [
    "tuner = Tuner(trainer)\n",
    "lr_finder = tuner.lr_find(model, datamodule=data_module,\n",
    "                          min_lr=1e-5, max_lr= 0.1,\n",
    "                          num_training=100, early_stop_threshold=4)\n",
    "fig = lr_finder.plot(suggest=True, show=True)\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e6d2d7a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original suggested learning rate: 0.002089296130854039\n",
      "Rounded suggested learning rate: 0.002\n"
     ]
    }
   ],
   "source": [
    "import math\n",
    "suggested_lr = lr_finder.suggestion()\n",
    "print(f\"Original suggested learning rate: {suggested_lr}\")\n",
    "\n",
    "# Round the suggested learning rate to 1 significant digit\n",
    "magnitude =  10 ** (math.floor(math.log10(suggested_lr)))\n",
    "suggested_lr = round(suggested_lr / magnitude) * magnitude\n",
    "\n",
    "print(f\"Rounded suggested learning rate: {suggested_lr}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7fa5579",
   "metadata": {},
   "source": [
    "## **3. Train Segmentation Model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c061e498",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_module =  AerialDeadTreeSegDataModule(\n",
    "    val_split=0.1, test_split=0.2, seed=42,\n",
    "    modality=\"merged\", # in_channels=4. If modality is \"merged\", it will use 4 channels (RGB + NIR); Otherwise, it will use 3 channels (RGB).\n",
    "    batch_size=32,\n",
    "    num_workers= int(os.cpu_count() / 2) if os.cpu_count() is not None else 0,\n",
    "    target_size=TARGET_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "87ec1c33",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_sum_callback = RichModelSummary(max_depth=2)\n",
    "\n",
    "lr_monitor = LearningRateMonitor(logging_interval='step')\n",
    "\n",
    "early_stop_callback = EarlyStopping(\n",
    "    monitor=\"per_image_iou/val\",\n",
    "    patience=10,\n",
    "    verbose=True,\n",
    "    mode=\"max\"  # Maximize the metric\n",
    ")\n",
    "\n",
    "checkpoint_callback = ModelCheckpoint(\n",
    "    dirpath=os.path.join(paths.checkpoint_dir, f\"smp_{ENCODER_NAME}_{ARCH}\", VERSION),\n",
    "    monitor=\"per_image_iou/val\",\n",
    "    filename=\"{epoch:02d}-{per_image_iou_val:.4f}\",\n",
    "    mode=\"max\",\n",
    "    save_top_k=3,\n",
    "    enable_version_counter=True,\n",
    ")\n",
    "\n",
    "timer = TimerCallback()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "1ccac926",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Encoder layer names: ['patch_embed1', 'patch_embed2', 'patch_embed3', 'patch_embed4', 'block1', 'norm1', 'block2', 'norm2', 'block3', 'norm3', 'block4', 'norm4']\n"
     ]
    }
   ],
   "source": [
    "model = SMPLitModule(\n",
    "    arch=ARCH,\n",
    "    encoder_name=ENCODER_NAME,\n",
    "    encoder_weights=\"imagenet\",\n",
    "    in_channels=data_module.in_channels,\n",
    "    out_classes=1,  # Binary segmentation\n",
    "    loss1=LOSS1,\n",
    "    loss2=LOSS2,\n",
    "    lr=suggested_lr,\n",
    "    use_scheduler=True\n",
    ")\n",
    "\n",
    "layer_names = []\n",
    "for name, module in model.model.encoder.named_children():\n",
    "    layer_names.append(name)\n",
    "print(f\"Encoder layer names: {layer_names}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "21fc1e78",
   "metadata": {},
   "outputs": [],
   "source": [
    "# freeze_tool = FreezeSMPEncoderUtils()\n",
    "# freeze_tool(model, ENCODER_NAME, layers_range=(0, 2))  # Freeze the first 2 layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "9e35cb8a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Trainer already configured with model summary callbacks: [<class 'lightning.pytorch.callbacks.rich_model_summary.RichModelSummary'>]. Skipping setting a default `ModelSummary` callback.\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008000; text-decoration-color: #008000\">Using existing split: ../data_splits/data_split_42_70_10.csv</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[32mUsing existing split: ..\u001b[0m\u001b[32m/data_splits/\u001b[0m\u001b[32mdata_split_42_70_10.csv\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "Loading `train_dataloader` to estimate number of stepping batches.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
       "<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">   </span><span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\"> Name                    </span><span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\"> Type                        </span><span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\"> Params </span><span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\"> Mode  </span>\n",
       "\n",
       "<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 0 </span> model                    Unet                         84.7 M  train \n",
       "<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 1 </span> model.encoder            MixVisionTransformerEncoder  81.4 M  train \n",
       "<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 2 </span> model.decoder            UnetDecoder                   3.3 M  train \n",
       "<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 3 </span> model.segmentation_head  SegmentationHead                145  train \n",
       "<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 4 </span> loss_fn1                 JaccardLoss                       0  train \n",
       "<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 5 </span> loss_fn2                 FocalLoss                         0  train \n",
       "<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 6 </span> _default_loss            DiceLoss                          0  train \n",
       "\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\n",
       "\u001b[1;35m \u001b[0m\u001b[1;35m \u001b[0m\u001b[1;35m \u001b[0m\u001b[1;35m \u001b[0m\u001b[1;35mName                   \u001b[0m\u001b[1;35m \u001b[0m\u001b[1;35m \u001b[0m\u001b[1;35mType                       \u001b[0m\u001b[1;35m \u001b[0m\u001b[1;35m \u001b[0m\u001b[1;35mParams\u001b[0m\u001b[1;35m \u001b[0m\u001b[1;35m \u001b[0m\u001b[1;35mMode \u001b[0m\u001b[1;35m \u001b[0m\n",
       "\n",
       "\u001b[2m \u001b[0m\u001b[2m0\u001b[0m\u001b[2m \u001b[0m model                    Unet                         84.7 M  train \n",
       "\u001b[2m \u001b[0m\u001b[2m1\u001b[0m\u001b[2m \u001b[0m model.encoder            MixVisionTransformerEncoder  81.4 M  train \n",
       "\u001b[2m \u001b[0m\u001b[2m2\u001b[0m\u001b[2m \u001b[0m model.decoder            UnetDecoder                   3.3 M  train \n",
       "\u001b[2m \u001b[0m\u001b[2m3\u001b[0m\u001b[2m \u001b[0m model.segmentation_head  SegmentationHead                145  train \n",
       "\u001b[2m \u001b[0m\u001b[2m4\u001b[0m\u001b[2m \u001b[0m loss_fn1                 JaccardLoss                       0  train \n",
       "\u001b[2m \u001b[0m\u001b[2m5\u001b[0m\u001b[2m \u001b[0m loss_fn2                 FocalLoss                         0  train \n",
       "\u001b[2m \u001b[0m\u001b[2m6\u001b[0m\u001b[2m \u001b[0m _default_loss            DiceLoss                          0  train \n",
       "\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Trainable params</span>: 84.7 M                                                                                           \n",
       "<span style=\"font-weight: bold\">Non-trainable params</span>: 0                                                                                            \n",
       "<span style=\"font-weight: bold\">Total params</span>: 84.7 M                                                                                               \n",
       "<span style=\"font-weight: bold\">Total estimated model params size (MB)</span>: 338                                                                        \n",
       "<span style=\"font-weight: bold\">Modules in train mode</span>: 1086                                                                                        \n",
       "<span style=\"font-weight: bold\">Modules in eval mode</span>: 0                                                                                            \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mTrainable params\u001b[0m: 84.7 M                                                                                           \n",
       "\u001b[1mNon-trainable params\u001b[0m: 0                                                                                            \n",
       "\u001b[1mTotal params\u001b[0m: 84.7 M                                                                                               \n",
       "\u001b[1mTotal estimated model params size (MB)\u001b[0m: 338                                                                        \n",
       "\u001b[1mModules in train mode\u001b[0m: 1086                                                                                        \n",
       "\u001b[1mModules in eval mode\u001b[0m: 0                                                                                            \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d9a3f7ca318a44a0afb4445ba5d6febc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Sanity Checking: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2bc5d915fae14c9a913f242d8221dc1b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fe35da81249e4896a797dad7fd39acea",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Metric per_image_iou/val improved. New best score: 0.019\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "37c9c2b225a141fc9c60b54233a0c9cc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Metric per_image_iou/val improved by 0.001 >= min_delta = 0.0. New best score: 0.019\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "427bd611fcc94f57bf80b110421cd2cb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7a4dac005a074e2cb79f81b223b5c9a2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Metric per_image_iou/val improved by 0.036 >= min_delta = 0.0. New best score: 0.055\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b13b15230fa1411b87a5f3785298bf6b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Metric per_image_iou/val improved by 0.113 >= min_delta = 0.0. New best score: 0.168\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3e595a864d0641789741f1a22ab46835",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Metric per_image_iou/val improved by 0.025 >= min_delta = 0.0. New best score: 0.193\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bade547c268c49ce952590e533163431",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e97bea2ce6b54d7499d62aa81de03b71",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Metric per_image_iou/val improved by 0.017 >= min_delta = 0.0. New best score: 0.210\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "57a52e966b2941b8b2a3b03daecd48d3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Metric per_image_iou/val improved by 0.004 >= min_delta = 0.0. New best score: 0.214\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4b3216783e1a4ffaa5e2430b280acd38",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Metric per_image_iou/val improved by 0.047 >= min_delta = 0.0. New best score: 0.260\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "81278ec7094d48b9ba3c9b0124a15827",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Metric per_image_iou/val improved by 0.083 >= min_delta = 0.0. New best score: 0.344\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "63a4dc3868124c858ec371ecfeeedeb5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ca694a90bb8e4aee82b9988b93f8fdaf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0bcc1e81e76844f48997d92762b9bab3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Metric per_image_iou/val improved by 0.008 >= min_delta = 0.0. New best score: 0.351\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0f4e240a491c4e2ba3ce35f02a8a8e2e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Metric per_image_iou/val improved by 0.026 >= min_delta = 0.0. New best score: 0.377\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f565d2397daa40f185f042787d425dd7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "67680c1c2e4d4ede8f400fad52af9f27",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "33829d181f5349c1bab79b41d594651a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "28838cdfe1d54180b0af2b1f83b4651d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "edd5e96e54194561830c569756b5e1eb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Metric per_image_iou/val improved by 0.000 >= min_delta = 0.0. New best score: 0.377\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "23f336a58e344673a8739c73e8853862",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Metric per_image_iou/val improved by 0.014 >= min_delta = 0.0. New best score: 0.391\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "22c16412a9ba4ef8bbc6cd67b88574d8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9300021dc7584f92a4c555e8974c1811",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3e6d3ac04e8d44ac9db8969e949555a9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c881f64b292d460ab4537ab880586e41",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Metric per_image_iou/val improved by 0.020 >= min_delta = 0.0. New best score: 0.412\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d604b01843b7487ea9bf53bffdc096c3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2a3fbebc99ee407984bfd97de9fda855",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c096cca48ffa403c9957b95d9065ddfb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4e9dfcd19dc74b23b2e153b67bcf1b3e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a2135d98f19c46ae825fb072b704de40",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ac363e532ce34f01aaf46f2c193adeb0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c80748f51ad04b5f96e8fc01aecbcbf3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4f2f90a020a6460993a49d25be3c9d5f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8424dcc89f894c0c89b1fb630d7d23fa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "271b4fa9c13e4eb3a7a4b4284a97180c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Monitored metric per_image_iou/val did not improve in the last 10 records. Best score: 0.412. Signaling Trainer to stop.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #000080; text-decoration-color: #000080\">Teardown called, cleaning up datasets...</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[34mTeardown called, cleaning up datasets\u001b[0m\u001b[34m...\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "logger = TensorBoardLogger(paths.tensorboard_log_dir, name=f\"smp_{ENCODER_NAME}_{ARCH}\", version=VERSION)\n",
    "\n",
    "trainer = L.Trainer(\n",
    "    max_epochs=100,\n",
    "    enable_progress_bar=True,\n",
    "    logger=logger,\n",
    "    callbacks=[model_sum_callback,lr_monitor, early_stop_callback, checkpoint_callback],\n",
    "    log_every_n_steps=5,\n",
    ")\n",
    "trainer.fit(model, datamodule=data_module)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "CVers",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
