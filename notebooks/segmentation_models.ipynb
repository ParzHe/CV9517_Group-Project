{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "eefe3629",
   "metadata": {},
   "source": [
    "# **COMP9517 - Group Project (Segmentation Models Pytorch)**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb76af11",
   "metadata": {},
   "source": [
    "## **0. Add Imports**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16f037ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !conda env create -f environment.yaml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45474d93",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "sys.path.append(os.path.join(os.getcwd(), '..'))\n",
    "\n",
    "import lightning as L\n",
    "from lightning.pytorch.callbacks import ModelCheckpoint, LearningRateMonitor, EarlyStopping, RichModelSummary, Timer\n",
    "from lightning.pytorch.loggers import TensorBoardLogger, WandbLogger\n",
    "\n",
    "from data import AerialDeadTreeSegDataModule, download_dataset\n",
    "from lightning.pytorch.tuner import Tuner\n",
    "from lightning_modules import SMPLitModule\n",
    "from models import FreezeSMPEncoderUtils\n",
    "from utils import paths\n",
    "import segmentation_models_pytorch as smp\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bfcd838",
   "metadata": {},
   "outputs": [],
   "source": [
    "ARCH = \"Unet\"\n",
    "ENCODER_NAME = \"efficientnet-b5\"\n",
    "MODALITY = \"merged\"\n",
    "TARGET_SIZE = 256\n",
    "VERSION = f\"{MODALITY}_{TARGET_SIZE}\"\n",
    "BATCH_SIZE = 32\n",
    "MAX_EPOCHS = 100\n",
    "EARLY_STOPPING_PATIENCE = 20\n",
    "LOSS1 = smp.losses.JaccardLoss(mode='binary', from_logits=True)\n",
    "LOSS2 = smp.losses.FocalLoss(mode='binary')\n",
    "MIN_LR = 1e-3\n",
    "MAX_LR = 0.1  # Maximum learning rate for the learning rate finder\n",
    "PRECISION = \"bf16-mixed\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bfbd7cde",
   "metadata": {},
   "source": [
    "## **1. Simple Summary of the Dattaset**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ed9f2b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "# Get the data folder\n",
    "data_folder = download_dataset()\n",
    "\n",
    "rgb_dir = os.path.join(data_folder, \"RGB_images\")\n",
    "nrg_dir = os.path.join(data_folder, \"NRG_images\")\n",
    "mask_dir = os.path.join(data_folder, \"masks\")\n",
    "\n",
    "# Get the max and min resolution of the images\n",
    "def get_max_min_resolution(image_dir):\n",
    "    max_res = (0, 0)\n",
    "    min_res = (float('inf'), float('inf'))\n",
    "    for filename in os.listdir(image_dir):\n",
    "        if filename.endswith(\".png\"):\n",
    "            filepath = os.path.join(image_dir, filename)\n",
    "            with open(filepath, 'rb') as f:\n",
    "                img = Image.open(f)\n",
    "                height, width = img.size\n",
    "                max_res = (max(max_res[0], height), max(max_res[1], width))\n",
    "                min_res = (min(min_res[0], height), min(min_res[1], width))\n",
    "    return max_res, min_res\n",
    "max_rgb_res, min_rgb_res = get_max_min_resolution(rgb_dir)\n",
    "max_nrg_res, min_nrg_res = get_max_min_resolution(nrg_dir)\n",
    "print(f\"Max RGB resolution: {max_rgb_res}, Min RGB resolution: {min_rgb_res}\")\n",
    "print(f\"Max NRG resolution: {max_nrg_res}, Min NRG resolution: {min_nrg_res}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7db092b",
   "metadata": {},
   "source": [
    "## **2. Prepare Data Module**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2df12677",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_module = AerialDeadTreeSegDataModule(\n",
    "    val_split=0.1, test_split=0.2, seed=42,\n",
    "    modality=MODALITY, # in_channels=4. If modality is \"merged\", it will use 4 channels (RGB + NIR); Otherwise, it will use 3 channels (RGB).\n",
    "    batch_size=BATCH_SIZE,\n",
    "    num_workers= int(os.cpu_count() / 2) if os.cpu_count() is not None else 0,\n",
    "    target_size=TARGET_SIZE)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "525ec884",
   "metadata": {},
   "source": [
    "## **3. Create Segmentation Models**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03d1d709",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = SMPLitModule(\n",
    "    arch=ARCH,\n",
    "    encoder_name=ENCODER_NAME,\n",
    "    encoder_weights=\"imagenet\",\n",
    "    in_channels=data_module.in_channels,\n",
    "    out_classes=1,  # Binary segmentation\n",
    "    loss1=LOSS1,\n",
    "    loss2=LOSS2,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b1266e6",
   "metadata": {},
   "source": [
    "## **4. Create Trainer**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa07a5a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_sum_callback = RichModelSummary(max_depth=2)\n",
    "\n",
    "lr_monitor = LearningRateMonitor(logging_interval='step')\n",
    "\n",
    "early_stop_callback = EarlyStopping(\n",
    "    monitor=\"per_image_iou/val\",\n",
    "    patience=EARLY_STOPPING_PATIENCE,\n",
    "    verbose=True,\n",
    "    mode=\"max\"  # Maximize the metric\n",
    ")\n",
    "\n",
    "timer = Timer(interval=\"epoch\", verbose=False)\n",
    "                \n",
    "checkpoint_callback = ModelCheckpoint(\n",
    "    dirpath=os.path.join(paths.checkpoint_dir, f\"smp_{ENCODER_NAME}_{ARCH}\", VERSION),\n",
    "    monitor=\"per_image_iou/val\",\n",
    "    filename=\"{epoch:02d}-{per_image_iou_val:.4f}\",\n",
    "    mode=\"max\",\n",
    "    save_top_k=2,\n",
    "    enable_version_counter=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8744c046",
   "metadata": {},
   "outputs": [],
   "source": [
    "logger = TensorBoardLogger(paths.tensorboard_log_dir, name=f\"smp_{ENCODER_NAME}_{ARCH}\", version=VERSION)\n",
    "trainer = L.Trainer(\n",
    "    precision=PRECISION,\n",
    "    max_epochs=MAX_EPOCHS,\n",
    "    enable_progress_bar=True,\n",
    "    logger=logger,\n",
    "    callbacks=[\n",
    "        model_sum_callback,\n",
    "        lr_monitor,\n",
    "        early_stop_callback,\n",
    "        timer,\n",
    "        checkpoint_callback\n",
    "    ],\n",
    "    log_every_n_steps=5,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2eb89776",
   "metadata": {},
   "source": [
    "## **5. Find Suggested Learning Rate**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "497bc6a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "tuner = Tuner(trainer)\n",
    "lr_finder = tuner.lr_find(model, datamodule=data_module,\n",
    "                          min_lr=MIN_LR, max_lr=MAX_LR,\n",
    "                          num_training=100, early_stop_threshold=4)\n",
    "fig = lr_finder.plot(suggest=True, show=True)\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7fa5579",
   "metadata": {},
   "source": [
    "## **6. Train and Test Segmentation Model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e35cb8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.fit(model, datamodule=data_module)\n",
    "print(\"Training starting time: \", timer.start_time(\"train\"))\n",
    "print(\"Time elapsed: \", timer.time_elapsed(\"train\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67dfcd4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.test(model, datamodule=data_module)\n",
    "print(\"Time elapsed: \", timer.time_elapsed(\"test\"))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "CVers",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
